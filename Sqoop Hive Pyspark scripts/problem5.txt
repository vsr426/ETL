Problem Scenario 5 [SQOOP]
CCA 175 Hadoop and Spark Developer Exam Preparation - Problem Scenario 5
PLEASE READ THE INTRODUCTION TO THIS SERIES. CLICK ON HOME LINK AND READ THE INTRO BEFORE ATTEMPTING TO SOLVE THE PROBLEMS

Video walkthrough of this problem is available at [PART 1 CLICK HERE] AND [PART 2 CLICK HERE]

Click here for the video version of this series. This takes you to the youtube playlist of videos. 

Sqoop is one of the important topics for the exam. Based on generally reported exam pattern from anonymous internet bloggers, you can expect 2 out of 10 questions on this topic related to Data Ingest and Data Export using Sqoop. Hence, 20% of the exam score can be obtained just by practicing simple Sqoop concepts. Sqoop can be mastered easily (i.e in a few hours) at the skill level that CCA 175 exam is expecting you to demonstrate. I created this problem focusing on Sqoop alone, if you are able to perform this exercise on your own or at worst using just the sqoop user guide then there is a very very high chance that you can score the 20% easily.

Pre-Work: Please perform these steps before solving the problem
1. Login to MySQL using below commands on a fresh terminal window
    mysql -u retail_dba -p
    Password = cloudera
2. Create a replica product table and name it products_replica
    create table products_replica as select * from products
3. Add primary key to the newly created table
    alter table products_replica add primary key (product_id);
4. Add two more columns
    alter table products_replica add column (product_grade int, product_sentiment varchar(100))
5. Run below two update statements to modify the data
    update products_replica set product_grade = 1  where product_price > 500;
    update products_replica set product_sentiment  = 'WEAK'  where product_price between 300 and  500;
    
Problem 5: Above steps are important so please complete them successfully before attempting to solve the problem
	Using sqoop, import products_replica table from MYSQL into hdfs such that fields are separated by a '|' and lines are separated by '\n'. Null values are represented as -1 for numbers and "NOT-AVAILABLE" for strings. Only records with product id greater than or equal to 1 and less than or equal to 1000 should be imported and use 3 mappers for importing. The destination file should be stored as a text file to directory  /user/cloudera/problem5/products-text. 
	Using sqoop, import products_replica table from MYSQL into hdfs such that fields are separated by a '*' and lines are separated by '\n'. Null values are represented as -1000 for numbers and "NA" for strings. Only records with product id less than or equal to 1111 should be imported and use 2 mappers for importing. The destination file should be stored as a text file to directory  /user/cloudera/problem5/products-text-part1. 
	Using sqoop, import products_replica table from MYSQL into hdfs such that fields are separated by a '*' and lines are separated by '\n'. Null values are represented as -1000 for numbers and "NA" for strings. Only records with product id greater than 1111 should be imported and use 5 mappers for importing. The destination file should be stored as a text file to directory  /user/cloudera/problem5/products-text-part2.
	Using sqoop merge data available in /user/cloudera/problem5/products-text-part1 and /user/cloudera/problem5/products-text-part2 to produce a new set of files in /user/cloudera/problem5/products-text-both-parts
	Using sqoop do the following. Read the entire steps before you create the sqoop job.
		create a sqoop job Import Products_replica table as text file to directory /user/cloudera/problem5/products-incremental. Import all the records.
		insert three more records to Products_replica from mysql
		run the sqoop job again so that only newly added records can be pulled from mysql
		insert 2 more records to Products_replica from mysql
		run the sqoop job again so that only newly added records can be pulled from mysql
		Validate to make sure the records have not be duplicated in HDFS
	Using sqoop do the following. Read the entire steps before you create the sqoop job.
		create a hive table in database named problem5 using below command 
		create table products_hive  (product_id int, product_category_id int, product_name string, product_description string, product_price float, product_imaage string,product_grade int,  product_sentiment string);
		create a sqoop job Import Products_replica table as hive table to database named problem5. name the table as products_hive. 
		insert three more records to Products_replica from mysql
		run the sqoop job again so that only newly added records can be pulled from mysql
		insert 2 more records to Products_replica from mysql
		run the sqoop job again so that only newly added records can be pulled from mysql
		Validate to make sure the records have not been duplicated in Hive table
	Using sqoop do the following. .
		insert 2 more records into products_hive table using hive. 
		create table in mysql using below command   
		create table products_external  (product_id int(11) primary Key, product_grade int(11), product_category_id int(11), product_name varchar(100), product_description varchar(100), product_price float, product_impage varchar(500), product_sentiment varchar(100));
		export data from products_hive (hive) table to (mysql) products_external table. 
		insert 2 more records to Products_hive table from hive
		export data from products_hive table to products_external table. 
		Validate to make sure the records have not be duplicated in mysql table

sqoop import --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" --username retail_dba --password cloudera --table products_replica --fields-terminated-by '|' --lines-terminated-by '\n' --where "product_id between 1 and 1000" -num-mappers 3 --target-dir /user/cloudera/problem5/products-text --null-string "NOT-AVAILABLE" --null-non-string "-1" --outdir javafiles
sqoop import --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" --username retail_dba --password cloudera --fields-terminated-by '*' --lines-terminated-by '\n' --null-string "NA" --null-non-string "-1000" --where "product_id <=1111" --num-mappers 2 --boundary-query "select 1 as min, 1111 as max from products_replica" --query "select * from products_replica where \$CONDITIONS" --split-by "product_id" --target-dir /user/cloudera/problem5/products-text-part1
sqoop import --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" --username retail_dba --password cloudera --fields-terminated-by '*' --lines-terminated-by '\n' --null-string "NA" --null-non-string "-1000" --where "product_id >1111" --num-mappers 2 --boundary-query "select 1111 as min, max(product_id) as max from products_replica" --query "select * from products_replica where \$CONDITIONS" --split-by "product_id" --target-dir /user/cloudera/problem5/products-text-part2

/tmp/sqoop-cloudera/compile/e3337929e50e009c6071845fe5a6dcb9/QueryResult.jar
/tmp/sqoop-cloudera/compile/e3337929e50e009c6071845fe5a6dcb9/QueryResult.java
/tmp/sqoop-cloudera/compile/2e879a423d6a777c94cee4fbe4dae52c/QueryResult.jar

sqoop merge --class-name "QueryResult" --jar-file "/tmp/sqoop-cloudera/compile/e3337929e50e009c6071845fe5a6dcb9/QueryResult.jar" --merge-key "product_id" --new-data "/user/cloudera/problem5/products-text-part2" --onto "/user/cloudera/problem5/products-text-part1" --target-dir "/user/cloudera/problem5/products-text-both-parts"


sqoop job import_products_replcia -- import --connect "jdbc:mysql://quickstart.cloudera:3306/retail_db" --username retail_dba --password cloudera --table products_replica --target-dir "/user/cloudera/problem5/products-incremental" --outdir javafiles
sqoop job --help
sqoop job --list
